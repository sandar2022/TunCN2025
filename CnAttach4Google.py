import streamlit as st
from gtts import gTTS
import io
import requests
import pandas as pd
import re
import pytesseract
from PIL import Image
import os
from google.cloud import vision
from google.cloud import translate_v2 as translate
GOOGLE_API_KEY = "AIzaSyBZSRyGFaD660vlPAeibkkDjlLNgClI4o0"

def google_translate_chinese_to_english(text):
    """Translate Chinese text using Google Translate REST API + API key"""
    try:
        url = "https://translation.googleapis.com/language/translate/v2"
        params = {
            "q": text,
            "source": "zh-CN",
            "target": "en",
            "format": "text",
            "key": GOOGLE_API_KEY
        }
        response = requests.post(url, data=params)
        result = response.json()
        
        if "data" in result and "translations" in result["data"]:
            translated = result["data"]["translations"][0]["translatedText"]
            return translated
        else:
            return "Translation unavailable"
    except Exception as e:
        return f"Error: {e}"

def google_ocr_extract_chinese(image):
    """Use Google Cloud Vision API to extract Chinese text"""
    try:
        client = vision.ImageAnnotatorClient()

        # Convert PIL Image to bytes
        img_byte_arr = io.BytesIO()
        image.save(img_byte_arr, format='PNG')
        content = img_byte_arr.getvalue()

        image_vision = vision.Image(content=content)
        response = client.text_detection(image=image_vision)

        if response.error.message:
            st.warning(f"Google OCR Error: {response.error.message}")
            return ""

        if response.text_annotations:
            return response.text_annotations[0].description.strip()
        else:
            return ""
    except Exception as e:
        st.error(f"Google OCR failed: {e}")
        return ""


# Set page configuration
st.set_page_config(
    page_title="Chinese Dictionary Explorer",
    page_icon="üéå",
    layout="wide"
)

# Configure Tesseract path
try:
    possible_paths = [
        r'C:\Program Files\Tesseract-OCR\tesseract.exe',
        r'C:\Program Files (x86)\Tesseract-OCR\tesseract.exe',
    ]
    
    tesseract_found = False
    for path in possible_paths:
        if os.path.exists(path):
            pytesseract.pytesseract.tesseract_cmd = path
            tesseract_found = True
            break
    
    OCR_AVAILABLE = tesseract_found
    if OCR_AVAILABLE:
        st.sidebar.success("‚úÖ Tesseract OCR Enabled")
    else:
        st.sidebar.warning("‚ö†Ô∏è Tesseract not found")
except:
    OCR_AVAILABLE = False
    st.sidebar.warning("‚ö†Ô∏è OCR features disabled")

# Initialize session state
if 'scanned_words' not in st.session_state:
    st.session_state.scanned_words = []
if 'extracted_text' not in st.session_state:
    st.session_state.extracted_text = ""
if 'word_details' not in st.session_state:
    st.session_state.word_details = {}
if 'manual_words' not in st.session_state:
    st.session_state.manual_words = []

def extract_individual_chinese_words(text):
    """Extract individual Chinese words from text"""
    chinese_words = re.findall(r'[\u4e00-\u9fff]{1,4}', text)
    
    # Remove duplicates while preserving order
    seen = set()
    unique_words = []
    for word in chinese_words:
        if word not in seen:
            seen.add(word)
            unique_words.append(word)
    
    return unique_words

def process_image_with_ocr(image):
    """Process image with OCR and extract Chinese text"""
    try:
        try:
            custom_config = r'--oem 3 --psm 6 -c preserve_interword_spaces=1'
            text = pytesseract.image_to_string(image, lang='chi_sim', config=custom_config)
        except:
            custom_config = r'--oem 3 --psm 6 -c preserve_interword_spaces=1'
            text = pytesseract.image_to_string(image, lang='eng', config=custom_config)
        
        return text.strip()
    except Exception as e:
        return f"OCR Error: {e}"

def process_uploaded_file(uploaded_file):
    """Process uploaded file and extract Chinese words"""
    try:
        if uploaded_file.type.startswith('image/'):
            if not OCR_AVAILABLE:
                return [], "OCR not available. Please install Tesseract."
            
            image = Image.open(uploaded_file)
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            width, height = image.size
            if width < 800 or height < 800:
                new_size = (max(800, width), max(800, height))
                image = image.resize(new_size, Image.Resampling.LANCZOS)
            
            extracted_text = process_image_with_ocr(image)
            
            if extracted_text and not extracted_text.startswith("OCR Error"):
                words = extract_individual_chinese_words(extracted_text)
                return words, extracted_text
            else:
                return [], extracted_text
                
        elif uploaded_file.type == 'text/plain':
            text = uploaded_file.getvalue().decode('utf-8')
            words = extract_individual_chinese_words(text)
            return words, text
            
        else:
            return [], "Unsupported file type"
            
    except Exception as e:
        return [], f"Error: {str(e)}"

def search_online_dictionary(word):
    """Search online Chinese dictionaries for word meaning"""
    try:
        # Try multiple API endpoints for better coverage
        apis = [
            (f"https://hanzi-api.vercel.app/api/definition/{word}", "HanziAPI"),
            (f"https://cc-cedict.org/wiki/search:{word}", "CC-CEDICT"),
        ]
        
        for api_url, source in apis:
            try:
                response = requests.get(api_url, timeout=5)
                if response.status_code == 200:
                    data = response.json()
                    if data and 'definition' in data:
                        return {
                            "pinyin": data.get('pinyin', 'N/A'),
                            "meaning": data['definition'],
                            "source": source
                        }
            except:
                continue
        
        return None
    except Exception as e:
        return None

def generate_smart_meaning(word):
    """Generate a smart meaning for unknown words using comprehensive character analysis"""
    
    # EXPANDED COMPREHENSIVE CHARACTER MEANINGS DICTIONARY
    char_meanings = {
        # Common nouns - people
        "Áà∏": "father", "Áà∑": "grandfather", "Â•∂": "grandmother", "Â¶à": "mother",
        "Âì•": "older brother", "Âºü": "younger brother", "Âßê": "older sister", 
        "Â¶π": "younger sister", "ÂÖÑ": "older brother", "Êúã": "friend", "Âèã": "friend",
        "Â≠ê": "child", "Â•≥": "woman", "Áî∑": "man", "Â≠©": "child", "ÂÑø": "child",
        "‰∫≤": "parent/relative", "Êàö": "relative", "ÂÆ∂": "family/home", "Â±û": "belong/relative",
        
        # Additional family members
        "ËàÖ": "maternal uncle", "Âß®": "maternal aunt", "‰ºØ": "paternal uncle", 
        "Âèî": "paternal uncle", "Âßë": "paternal aunt", "Â©∂": "aunt (wife of father's younger brother)",
        "‰æÑ": "nephew", "Áî•": "nephew (sister's son)", "Â≠ô": "grandchild",
        
        # Additional actions
        "Ëµ∑": "rise", "Á´ã": "stand", "Âùê": "sit", "‰∏ã": "down", "‰∏æ": "lift", "Êâã": "hand",
        
        # Professions & social
        "Â∑•": "work/worker", "‰∫∫": "person", "Ê∏î": "fishing", "Âåª": "medical", 
        "Áîü": "life/student", "ÂÜú": "farming", "ËÄÅ": "old", "Â∏à": "teacher", 
        "Â≠¶": "study", "Ê†°": "school", "Áîü": "life/student", "Âëò": "member", 
        "Ë≠¶": "police", "ÂÖµ": "soldier", "ÂïÜ": "business", "ÂÆò": "official",
        "Ê∞ë": "people", "‰ºó": "crowd", "Áæ§": "group", "Èòü": "team",
        
        # Education & writing
        "ËØª": "read", "‰π¶": "book", "ÂÜô": "write", "Â≠ó": "character", "Áîª": "draw/painting",
        "Êñá": "language/writing", "Á´†": "chapter", "Á¨î": "pen", "Á∫∏": "paper", "Êïô": "teach",
        "ËØæ": "lesson", "Êú¨": "book", "Áü•": "know", "ËØÜ": "knowledge", "ËÄÉ": "test",
        
        # Communication
        "ËØ¥": "speak", "ËØù": "speech", "Âî±": "sing", "Ê≠å": "song", "ËØ≠": "language",
        "Ë®Ä": "speech", "Ë∞à": "talk", "ËÆ≤": "speak", "Âëä": "tell", "ËØâ": "tell",
        "ÈóÆ": "ask", "Á≠î": "answer", "Âè´": "call", "Âñä": "shout",
        
        # Actions & verbs
        "Êãç": "pat/clap", "ÂÅö": "do", "‰Ωú": "do/make", "Ëµ∞": "walk", "Ë∑ë": "run",
        "ÂêÉ": "eat", "Âñù": "drink", "Áúã": "look/see", "Âê¨": "listen", "‰π∞": "buy",
        "Âçñ": "sell", "Êù•": "come", "Âéª": "go", "ÂºÄ": "open", "ÂÖ≥": "close",
        "Âùê": "sit", "Á´ô": "stand", "Áù°": "sleep", "ÈÜí": "wake", "Áé©": "play",
        "Á¨ë": "laugh", "Âì≠": "cry", "ÊÉ≥": "think", "ÊÄù": "think", "Áà±": "love",
        "Âñú": "like", "Ê¨¢": "happy", "ÊÅ®": "hate", "ÊÄï": "fear", "Âøò": "forget",
        "ËÆ∞": "remember", "Êâæ": "find", "ÂØª": "search", "Á≠â": "wait", "ÂÅú": "stop",
        "Âßã": "begin", "Áªà": "end", "Âèò": "change", "Âåñ": "change", "Âèë": "send/develop",
        "Â±ï": "develop", "Ëøõ": "enter/advance", "Âá∫": "exit", "ÂÖ•": "enter",
        "Âõû": "return", "Âà∞": "arrive", "Ëøá": "pass", "Áªè": "pass through",
        "ÈÄö": "pass through", "Ë°å": "go/ok", "Âä®": "move", "Ê¥ª": "live", "Ê≠ª": "die",
        "Â∑•": "work", "‰Ωú": "work", "Âπ≤": "do", "Âäû": "handle", "ÁêÜ": "manage",
        "ÁÆ°": "manage", "Ê≤ª": "govern", "Âª∫": "build", "ÈÄ†": "make", "‰øÆ": "repair",
        "Êîπ": "change", "Èù©": "reform", "Âàõ": "create", "ÈÄ†": "create",
        
        # Body parts
        "Êâã": "hand", "Â§¥": "head", "ËÑö": "foot", "Áúº": "eye", "ËÄ≥": "ear",
        "Âè£": "mouth", "ÂøÉ": "heart", "Ë∫´": "body", "ËÑ∏": "face", "Èºª": "nose",
        "Ëàå": "tongue", "Áâô": "tooth", "Âèë": "hair", "ÁöÆ": "skin", "È™®": "bone",
        "Ë°Ä": "blood", "ËÇâ": "meat", "ËÑë": "brain", "ËÖø": "leg", "ËáÇ": "arm",
        
        # Objects & things
        "ÁêÉ": "ball", "Ë°£": "clothes", "Êúç": "clothes", "Ëä±": "flower", "Âõ≠": "garden",
        "Ê†ë": "tree", "Êú®": "wood", "Ê°•": "bridge", "ËΩ¶": "vehicle", "Êàø": "house",
        "Èó®": "door", "Á™ó": "window", "Ê°å": "table", "Ê§Ö": "chair", "Â∫ä": "bed",
        "ÁÅØ": "lamp", "Áîµ": "electricity", "Êú∫": "machine", "Âô®": "device", "ÂÖ∑": "tool",
        "ÂàÄ": "knife", "Á¢ó": "bowl", "ÊùØ": "cup", "Áì∂": "bottle", "Áõí": "box",
        "ÂåÖ": "bag", "ÁÆ±": "box", "Èí±": "money", "Èáë": "gold/money", "Èì∂": "silver",
        "Áü≥": "stone", "ÈìÅ": "iron", "Èí¢": "steel", "Áéâ": "jade", "ÂÆù": "treasure",
        
        # Nature & geography
        "Â§©": "sky/day", "Âú∞": "ground", "Ê∞¥": "water", "ÁÅ´": "fire", "Â±±": "mountain",
        "Áü≥": "stone", "Êó•": "sun/day", "Êúà": "moon/month", "Êòü": "star", "‰∫ë": "cloud",
        "Èõ®": "rain", "Èõ™": "snow", "È£é": "wind", "Èõ∑": "thunder", "Áîµ": "lightning",
        "Ê±ü": "river", "Ê≤≥": "river", "Êπñ": "lake", "Êµ∑": "sea", "Ê¥ã": "ocean",
        "ÊµÅ": "flow", "Ê≥â": "spring", "Ê≥¢": "wave", "Êµ™": "wave", "Â≤õ": "island",
        "Êûó": "forest", "Ê£Æ": "forest", "Áî∞": "field", "Âúü": "soil", "Ê≤ô": "sand",
        "Âéü": "plain", "Èáé": "field", "Ëçâ": "grass", "Ëä±": "flower", "Âè∂": "leaf",
        "Ê†π": "root", "Êûù": "branch", "Êûú": "fruit", "ÂÆû": "fruit", "Áßç": "seed",
        
        # Time & space
        "Âπ¥": "year", "Êúà": "month", "Êó•": "day", "Êó∂": "time", "Èó¥": "interval",
        "Âàª": "moment", "ÂàÜ": "minute", "Áßí": "second", "Â≠£": "season", "ËäÇ": "festival",
        "Êò•": "spring", "Â§è": "summer", "Áßã": "autumn", "ÂÜ¨": "winter", "Êô®": "morning",
        "Êôö": "evening/night", "Êó©": "morning/early", "Â§ú": "night", "Âçà": "noon",
        "‰ªä": "now", "Êòé": "bright/tomorrow", "Êò®": "yesterday", "Âéª": "past", "Êú™": "future",
        "‰∏ä": "up/above", "‰∏ã": "down/below", "‰∏≠": "middle", "Â∑¶": "left", "Âè≥": "right",
        "Ââç": "front", "Âêé": "back", "Èáå": "inside", "Â§ñ": "outside", "ÂÜÖ": "inside",
        "ÊóÅ": "side", "Ëæπ": "side", "Ëßí": "corner", "È°∂": "top", "Â∫ï": "bottom",
        "‰∏ú": "east", "Ë•ø": "west", "Âçó": "south", "Âåó": "north", "Êñπ": "direction",
        
        # Common adjectives/adverbs
        "Â§ß": "big", "Â∞è": "small", "Â§ö": "many", "Â∞ë": "few", "Èïø": "long", "Áü≠": "short",
        "È´ò": "tall/high", "‰Ωé": "low", "ÁÉ≠": "hot", "ÂÜ∑": "cold", "Êñ∞": "new", "Êóß": "old",
        "Â•Ω": "good", "Âùè": "bad", "Âø´": "fast", "ÊÖ¢": "slow", "Áæé": "beautiful", "‰∏ë": "ugly",
        "Âº∫": "strong", "Âº±": "weak", "Á°¨": "hard", "ËΩØ": "soft", "ËΩª": "light", "Èáç": "heavy",
        "Ëøú": "far", "Ëøë": "near", "Ê∑±": "deep", "ÊµÖ": "shallow", "ÂÆΩ": "wide", "Á™Ñ": "narrow",
        "Áõ¥": "straight", "ÂºØ": "curved", "Âπ≥": "flat", "ÂÆâ": "safe", "ÂÖ®": "complete",
        "Âç±": "dangerous", "Èô©": "dangerous", "Èöæ": "difficult", "Êòì": "easy", "ÁÆÄ": "simple",
        "Â§ç": "complex", "Ê∏Ö": "clear", "Ê•ö": "clear", "Ê®°": "vague", "Á≥ä": "blurry",
        "Áúü": "true", "ÂÅá": "false", "Ê≠£": "correct", "Èîô": "wrong", "ÂØπ": "correct",
        "Âêå": "same", "ÂºÇ": "different", "Áâπ": "special", "Âà´": "other", "ÊôÆ": "common",
        "ÈÄö": "common", "Â∏∏": "usual", "Â•á": "strange", "ÊÄ™": "strange",
        
        # Pronouns & particles
        "Êàë": "I/me", "‰Ω†": "you", "‰ªñ": "he/him", "Â•π": "she/her", "ÂÆÉ": "it",
        "‰ª¨": "plural marker", "Ëá™": "self", "Â∑±": "self", "ÂêÑ": "each", "ÊØè": "every",
        "Êüê": "certain", "Ëøô": "this", "ÈÇ£": "that", "Âì™": "which", "Ë∞Å": "who",
        "‰ªÄ": "what", "ÊÄé": "how", "‰Ωï": "what", "‰∏∫": "for/because", "Âõ†": "because",
        "Êûú": "result", "ËôΩ": "although", "ÁÑ∂": "however", "‰ΩÜ": "but", "ËÄå": "and",
        "‰∏î": "moreover", "Êàñ": "or", "‰πÉ": "is", "Âç≥": "namely", "Âàô": "then",
        "ËôΩ": "although", "ÁÑ∂": "thus", "‰ΩÜ": "but", "Âç¥": "but", "ÂÄí": "instead",
        "Âèç": "instead", "Á´ü": "unexpectedly", "ÂÅè": "insist on", "Â∞±": "then",
        "Êâç": "only then", "Âàö": "just", "Êõæ": "once", "Â∑≤": "already", "Áªè": "already",
        "Ê≠£": "just now", "Âú®": "at/in", "ÁùÄ": "aspect marker", "‰∫Ü": "completed action",
        "Ëøá": "experience marker", "ÁöÑ": "of", "Âú∞": "adverbial marker", "Âæó": "complement marker",
        "‰πã": "of", "‰πé": "question particle", "Âêó": "question particle", "Âë¢": "question particle",
        "Âêß": "suggestion particle", "Âïä": "exclamation", "ÂëÄ": "exclamation", "Âìá": "exclamation",
        "Âì¶": "oh", "ÂóØ": "uh-huh", "Âîâ": "alas", "ÂñÇ": "hello", "Âòø": "hey",
        
        # Numbers & quantities
        "‰∏Ä": "one", "‰∫å": "two", "‰∏â": "three", "Âõõ": "four", "‰∫î": "five",
        "ÂÖ≠": "six", "‰∏É": "seven", "ÂÖ´": "eight", "‰πù": "nine", "ÂçÅ": "ten",
        "Áôæ": "hundred", "ÂçÉ": "thousand", "‰∏á": "ten thousand", "‰∫ø": "hundred million",
        "Èõ∂": "zero", "Âçä": "half", "Âèå": "double", "ÂØπ": "pair", "Âçï": "single",
        "ÂÖ®": "whole", "Êï¥": "whole", "ÈÉ®": "part", "ÂàÜ": "part", "‰∫õ": "some",
        "ÁÇπ": "point", "Á¨¨": "ordinal prefix", "Âàù": "beginning",
        
        # Colors
        "Á∫¢": "red", "ÈªÑ": "yellow", "Ëìù": "blue", "Áªø": "green", "ÁôΩ": "white", "Èªë": "black",
        "Á¥´": "purple", "ÁÅ∞": "gray", "Á≤â": "pink", "Ê£ï": "brown", "Ê©ô": "orange",
        
        # Transportation & locations
        "Ë∑Ø": "road", "Ë°ó": "street", "ÈÅì": "road", "Â∑∑": "alley", "ÂºÑ": "lane",
        "ÂÖ¨": "public", "ÂÖ±": "common", "‰∫§": "traffic", "ÈÄö": "traffic", "Ëøê": "transport",
        "Ëæì": "transport", "ËΩ¶": "vehicle", "Ê±Ω": "steam", "ÁÅ´": "fire", "Ëàπ": "ship",
        "Ëà™": "navigation", "Á©∫": "air", "È£û": "fly", "Êú∫": "machine", "Âú∫": "field",
        "Á´ô": "station", "Ê∏Ø": "port", "Á†Å": "pier", "Â§¥": "head", "Âè£": "port",
        "Â≤∏": "shore", "Ëæπ": "side", "Áïå": "border", "Â¢É": "border", "ÂõΩ": "country",
        "ÂÆ∂": "country", "Â∑û": "state", "ÁúÅ": "province", "Â∏Ç": "city", "Âéø": "county",
        "Âå∫": "district", "Èïá": "town", "Êùë": "village", "Â∫Ñ": "village",
    }
    
    # EXPANDED COMMON WORD MEANINGS
    common_words = {
        # Basic greetings & phrases
        "‰Ω†Â•Ω": "hello", "ÊÇ®Â•Ω": "hello (formal)", "‰Ω†‰ª¨Â•Ω": "hello everyone", 
        "Â§ßÂÆ∂Â•Ω": "hello everyone", "Ë∞¢Ë∞¢": "thank you", "ÊÑüË∞¢": "thanks", 
        "Â§öË∞¢": "many thanks", "ÂØπ‰∏çËµ∑": "sorry", "Êä±Ê≠â": "apology", 
        "ËØ∑ÂéüË∞Ö": "please forgive", "Ê≤°ÂÖ≥Á≥ª": "it's okay", "‰∏çÂÆ¢Ê∞î": "you're welcome",
        "ËØ∑": "please", "ËØ∑ÈóÆ": "may I ask", "ÂÜçËßÅ": "goodbye", "ÂÜç‰ºö": "see you again",
        "ÊòéÂ§©ËßÅ": "see you tomorrow", "Ê¨¢Ëøé": "welcome", "Ê¨¢ËøéÂÖâ‰∏¥": "welcome",
        
        # Time & dates
        "‰ªäÂ§©": "today", "ÊòéÂ§©": "tomorrow", "Êò®Â§©": "yesterday", "Áé∞Âú®": "now",
        "ÂàöÊâç": "just now", "‰ª•Âêé": "later", "‰ª•Ââç": "before", "Â∞ÜÊù•": "future",
        "ËøáÂéª": "past", "Êó©‰∏ä": "morning", "Êó©Êô®": "morning", "‰∏≠Âçà": "noon",
        "‰∏ãÂçà": "afternoon", "Êôö‰∏ä": "evening", "Â§úÊôö": "night", "ÂçäÂ§ú": "midnight",
        "ÂàÜÈíü": "minute", "Â∞èÊó∂": "hour", "Êó∂Èó¥": "time", "Êó∂ÂÄô": "time",
        "Êó•Êúü": "date", "ÊòüÊúü": "week", "Âë®Êú´": "weekend", "Êúà‰ªΩ": "month",
        "Âπ¥‰ªΩ": "year", "Â≠£ËäÇ": "season", "Êò•Â§©": "spring", "Â§èÂ§©": "summer",
        "ÁßãÂ§©": "autumn", "ÂÜ¨Â§©": "winter",
        
        # People & relationships
        "ÊúãÂèã": "friend", "Â•ΩÊúãÂèã": "good friend", "Áî∑ÊúãÂèã": "boyfriend", 
        "Â•≥ÊúãÂèã": "girlfriend", "ÂÆ∂‰∫∫": "family", "ÂÆ∂Â∫≠": "family", 
        "Áà∂ÊØç": "parents", "Áà∂‰∫≤": "father", "ÊØç‰∫≤": "mother", "Áà∏Áà∏": "dad",
        "Â¶àÂ¶à": "mom", "ÂÑøÂ≠ê": "son", "Â•≥ÂÑø": "daughter", "ÂÖÑÂºü": "brothers",
        "ÂßêÂ¶π": "sisters", "Âì•Âì•": "older brother", "ÂºüÂºü": "younger brother",
        "ÂßêÂßê": "older sister", "Â¶πÂ¶π": "younger sister", "Áà∑Áà∑": "grandpa",
        "Â•∂Â•∂": "grandma", "ËÄÅÂ∏à": "teacher", "Â≠¶Áîü": "student", "ÂêåÂ≠¶": "classmate",
        "Âêå‰∫ã": "colleague", "ËÄÅÊùø": "boss", "ÂëòÂ∑•": "employee", "ÂåªÁîü": "doctor",
        "Êä§Â£´": "nurse", "Ë≠¶ÂØü": "police", "Âè∏Êú∫": "driver", "Â∑•‰∫∫": "worker",
        
        # Extended family relationships
        "ËàÖËàÖ": "maternal uncle", "ÈòøÂß®": "maternal aunt", "‰ºØ‰ºØ": "paternal uncle (older)",
        "ÂèîÂèî": "paternal uncle (younger)", "ÂßëÂßë": "paternal aunt", "Â©∂Â©∂": "aunt",
        "‰æÑÂ≠ê": "nephew", "‰æÑÂ•≥": "niece", "Â§ñÁî•": "nephew (sister's son)",
        "Â§ñÁî•Â•≥": "niece (sister's daughter)", "Â≠ôÂ≠ê": "grandson", "Â≠ôÂ•≥": "granddaughter",
        
        # Classroom commands & actions
        "Ëµ∑Á´ã": "stand up", "Âùê‰∏ã": "sit down", "‰∏æÊâã": "raise hand",
        
        # Education & school
        "Â≠¶Ê†°": "school", "Â§ßÂ≠¶": "university", "‰∏≠Â≠¶": "middle school", 
        "Â∞èÂ≠¶": "elementary school", "ÊïôÂÆ§": "classroom", "Â≠¶‰π†": "study",
        "ËØª‰π¶": "read/study", "ËÄÉËØï": "exam", "ÁªÉ‰π†": "practice", "‰Ωú‰∏ö": "homework",
        "ËØæÁ®ã": "course", "‰∏ì‰∏ö": "major", "ÊïôËÇ≤": "education", "Áü•ËØÜ": "knowledge",
        "ÊñáÂåñ": "culture", "ÁßëÂ≠¶": "science", "ÊäÄÊúØ": "technology", "Êï∞Â≠¶": "math",
        "ËØ≠Êñá": "language", "Ëã±ËØ≠": "English", "‰∏≠Êñá": "Chinese", "Â§ñËØ≠": "foreign language",
        
        # Work & business
        "Â∑•‰Ωú": "work", "‰∏äÁè≠": "go to work", "‰∏ãÁè≠": "get off work", 
        "ÂÖ¨Âè∏": "company", "ÂäûÂÖ¨ÂÆ§": "office", "‰ºöËÆÆ": "meeting", 
        "È°πÁõÆ": "project", "‰∏öÂä°": "business", "Â∏ÇÂú∫": "market", 
        "ÈîÄÂîÆ": "sales", "ÁÆ°ÁêÜ": "management", "ÁªèÁêÜ": "manager", 
        "Â∑•ËµÑ": "salary", "ËÅå‰∏ö": "occupation", " career": "career",
        
        # Food & drinks
        "È£üÁâ©": "food", "È£üÂìÅ": "food product", "ÂêÉÈ•≠": "eat meal", 
        "Êó©È§ê": "breakfast", "ÂçàÈ§ê": "lunch", "ÊôöÈ§ê": "dinner", 
        "Ê∞¥Êûú": "fruit", "ËãπÊûú": "apple", "È¶ôËïâ": "banana", "Ê©òÂ≠ê": "orange",
        "Ëî¨Ëèú": "vegetables", "Á±≥È•≠": "rice", "Èù¢Êù°": "noodles", "Èù¢ÂåÖ": "bread",
        "ËÇâÁ±ª": "meat", "ÁâõËÇâ": "beef", "Áå™ËÇâ": "pork", "È∏°ËÇâ": "chicken",
        "È±º": "fish", "Êµ∑È≤ú": "seafood", "Ê±§": "soup", "È•ÆÊñô": "drink",
        "Ê∞¥": "water", "Ëå∂": "tea", "ÂíñÂï°": "coffee", "ÁâõÂ•∂": "milk",
        "ÈÖí": "alcohol", "Âï§ÈÖí": "beer",
        
        # Home & daily life
        "ÂÆ∂": "home", "ÊàøÂ≠ê": "house", "ÊàøÈó¥": "room", "ÂçßÂÆ§": "bedroom",
        "Âé®Êàø": "kitchen", "Âç´ÁîüÈó¥": "bathroom", "ÂÆ¢ÂéÖ": "living room",
        "ÂÆ∂ÂÖ∑": "furniture", "Â∫ä": "bed", "Ê°åÂ≠ê": "table", "Ê§ÖÂ≠ê": "chair",
        "Èó®": "door", "Á™óÊà∑": "window", "ÁÅØ": "light", "ÁîµËßÜ": "TV",
        "ÁîµËÑë": "computer", "ÊâãÊú∫": "mobile phone", "ÁΩëÁªú": "internet",
        "Ë°£Êúç": "clothes", "ÈûãÂ≠ê": "shoes", "Â∏ΩÂ≠ê": "hat", "ÂåÖ": "bag",
        
        # Transportation
        "‰∫§ÈÄö": "transportation", "Ê±ΩËΩ¶": "car", "ÂÖ¨ÂÖ±Ê±ΩËΩ¶": "bus", 
        "Âú∞ÈìÅ": "subway", "ÁÅ´ËΩ¶": "train", "È£ûÊú∫": "airplane", 
        "Ëá™Ë°åËΩ¶": "bicycle", "Êë©ÊâòËΩ¶": "motorcycle", "Âá∫ÁßüËΩ¶": "taxi",
        "ËΩ¶Á´ô": "station", "Êú∫Âú∫": "airport", "Á†ÅÂ§¥": "pier", 
        "ÈÅìË∑Ø": "road", "ÂÖ¨Ë∑Ø": "highway", "Ë°óÈÅì": "street", "Ê°•Ê¢Å": "bridge",
        
        # Nature & geography
        "Ê≤≥ÊµÅ": "river", "Ê≤≥": "river", "ÊµÅ": "flow", 
        "Êµ∑Ê¥ã": "ocean", "Êµ∑": "sea", "Ê¥ã": "ocean",
        "Ê±üÊπñ": "rivers and lakes", "Êπñ": "lake",
        "Â§©Á©∫": "sky", "Â§©Ê∞î": "weather", "Ê∞îÂÄô": "climate",
        "Â§™Èò≥": "sun", "Êúà‰∫Æ": "moon", "ÊòüÊòü": "star", "Âú∞ÁêÉ": "earth",
        "Â±±": "mountain", "Â±±ËÑâ": "mountain range", "Â±±Â≥∞": "mountain peak",
        "Ê£ÆÊûó": "forest", "Ê†ëÊú®": "trees", "Ëä±Ëçâ": "flowers and plants",
        "Âä®Áâ©": "animals", "Ê§çÁâ©": "plants", "Ëá™ÁÑ∂": "nature",
        
        # Arts & entertainment
        "Èü≥‰πê": "music", "Ê≠åÊõ≤": "song", "Âî±Ê≠å": "sing", "Ë∑≥Ëàû": "dance",
        "ÁîµÂΩ±": "movie", "ÁîµËßÜ": "TV", "ËäÇÁõÆ": "program", "Ê∏∏Êàè": "game",
        "ËøêÂä®": "sports", "ÊØîËµõ": "competition", "Ëâ∫ÊúØ": "art", "ÊñáÂåñ": "culture",
        "ÁîªÂõæ": "drawing", "ÂõæÁîª": "picture", "ÁªòÁîª": "painting", "ÁæéÊúØ": "fine arts",
        "ÊñáÂ≠¶": "literature", "ÊïÖ‰∫ã": "story", "Â∞èËØ¥": "novel", "ËØóÊ≠å": "poetry",
        
        # Emotions & feelings
        "È´òÂÖ¥": "happy", "Âø´‰πê": "joyful", "ÂºÄÂøÉ": "happy", "Âπ∏Á¶è": "happiness",
        "ÊÇ≤‰º§": "sad", "ÈöæËøá": "sad", "ÁóõËã¶": "pain", "ÁîüÊ∞î": "angry",
        "ÊÑ§ÊÄí": "anger", "ÂÆ≥ÊÄï": "afraid", "ÊãÖÂøÉ": "worried", "Á¥ßÂº†": "nervous",
        "Áà±": "love", "ÂñúÊ¨¢": "like", "ËÆ®Âéå": "hate", "ÊÉ≥Âøµ": "miss",
        
        # Common verbs
        "ÊòØ": "is/am/are", "Êúâ": "have", "Âú®": "at/in", "Ë¶Å": "want",
        "ÊÉ≥": "think/want", "ÂèØ‰ª•": "can", "ËÉΩ": "can", "‰ºö": "can/know how",
        "Â∫îËØ•": "should", "ÂøÖÈ°ª": "must", "ÈúÄË¶Å": "need", "ËÆ©": "let",
        "Âè´": "call", "Êù•": "come", "Âéª": "go", "Âõû": "return",
        "Âà∞": "arrive", "Ëµ∞": "walk", "Ë∑ë": "run", "Á´ô": "stand",
        "Âùê": "sit", "ÂêÉ": "eat", "Âñù": "drink", "Áù°": "sleep",
        "‰π∞": "buy", "Âçñ": "sell", "ÂÅö": "do", "‰Ωú": "do/make",
        "Â∑•‰Ωú": "work", "Â≠¶‰π†": "study", "Áé©": "play", "Áúã": "look/see",
        "Âê¨": "listen", "ËØ¥": "speak", "ËØª": "read", "ÂÜô": "write",
        "ÈóÆ": "ask", "Á≠î": "answer", "Êâæ": "find", "Áî®": "use",
        
        # Question words
        "‰ªÄ‰πà": "what", "‰∏∫‰ªÄ‰πà": "why", "ÊÄé‰πà": "how", "Âì™Èáå": "where",
        "Âì™‰∏™": "which", "Ë∞Å": "who", "‰ªÄ‰πàÊó∂ÂÄô": "when", "Â§öÂ∞ë": "how much/many",
        
        # Countries & languages
        "‰∏≠ÂõΩ": "China", "‰∏≠Êñá": "Chinese", "Ê±âËØ≠": "Chinese language",
        "ÁæéÂõΩ": "America", "Ëã±ËØ≠": "English", "Ëã±ÂõΩ": "England",
        "Ê≥ïÂõΩ": "France", "Ê≥ïËØ≠": "French", "Âæ∑ÂõΩ": "Germany", 
        "Âæ∑ËØ≠": "German", "Êó•Êú¨": "Japan", "Êó•ËØ≠": "Japanese",
        "Èü©ÂõΩ": "Korea", "Èü©ËØ≠": "Korean", "‰øÑÁΩóÊñØ": "Russia",
        "‰øÑËØ≠": "Russian", "Ë•øÁè≠Áâô": "Spain", "Ë•øÁè≠ÁâôËØ≠": "Spanish",
        
        # Your specific words that were missing
        "ÂÖ¨Ë∑Ø": "highway/public road", "ÁîªÂõæ": "drawing/draw pictures", 
        "‰ª¨": "plural marker for pronouns", "Êµ∑Ê¥ã": "ocean", "Ê≤≥ÊµÅ": "river",
    }
    
    # First check if it's a common word we know
    if word in common_words:
        return common_words[word]
    
    # For single characters
    if len(word) == 1:
        return char_meanings.get(word, "Single character - meaning unknown")
    
    # For multi-character words, analyze components
    meaning_parts = []
    unknown_chars = []
    
    for char in word:
        if char in char_meanings:
            meaning_parts.append(char_meanings[char])
        else:
            unknown_chars.append(char)
    
    if meaning_parts:
        base_meaning = " + ".join(meaning_parts)
        if unknown_chars:
            return f"Based on characters: {base_meaning} + [unknown: {''.join(unknown_chars)}]"
        else:
            return f"Based on characters: {base_meaning}"
    else:
        return "Word meaning unknown - all characters unrecognized"

def generate_smart_pinyin(word):
    """Generate a plausible pinyin for unknown words"""
    pinyin_map = {
        'Áà∏': 'b√†', 'Áà∑': 'y√©', 'Â•∂': 'n«éi', 'Â¶à': 'mƒÅ', 'Âì•': 'gƒì', 'Âºü': 'd√¨',
        'Âßê': 'jiƒõ', 'Â¶π': 'm√®i', 'ÂÖÑ': 'xi≈çng', 'Â∑•': 'g≈çng', '‰∫∫': 'r√©n',
        'Âåª': 'yƒ´', 'Áîü': 'shƒìng', 'ÂÜú': 'n√≥ng', 'Â≠¶': 'xu√©', 'Ê†°': 'xi√†o',
        '‰∏ä': 'sh√†ng', '‰∏ã': 'xi√†', 'Êîæ': 'f√†ng', 'ËØª': 'd√∫', '‰π¶': 'sh≈´', 
        'ÂÜô': 'xiƒõ', 'Â≠ó': 'z√¨', 'ËØ¥': 'shu≈ç', 'ËØù': 'hu√†', 'Âî±': 'ch√†ng', 
        'Ê≠å': 'gƒì', 'ÂÅö': 'zu√≤', 'Êâã': 'sh«íu', '‰Ωú': 'zu√≤', '‰∏ö': 'y√®', 
        'Êãç': 'pƒÅi', 'ÁêÉ': 'qi√∫', 'Ëä±': 'huƒÅ', 'Âõ≠': 'yu√°n', 'Á©ø': 'chuƒÅn', 
        'Ë°£': 'yƒ´', 'Êúç': 'f√∫', 'Â§ß': 'd√†', 'Â∞è': 'xi«éo', 'Ê°•': 'qi√°o', 
        'Áîª': 'hu√†', 'Ê†ë': 'sh√π', 'Êôö': 'w«én', 'Êó©': 'z«éo', 'Â§©': 'tiƒÅn',
        'Êàë': 'w«í', '‰Ω†': 'n«ê', '‰ªñ': 'tƒÅ', 'Â•π': 'tƒÅ', 'ÊòØ': 'sh√¨', '‰∏ç': 'b√π',
        'Â•Ω': 'h«éo', 'Âæà': 'hƒõn', 'ÁöÑ': 'de', '‰∫Ü': 'le', 'Âú®': 'z√†i', 'Êúâ': 'y«íu',
        'Âíå': 'h√©', 'Ëøô': 'zh√®', 'ÈÇ£': 'n√†', '‰∏Ä': 'yƒ´', '‰∫å': '√®r', '‰∏â': 'sƒÅn',
        'Á∫¢': 'h√≥ng', 'ÈªÑ': 'hu√°ng', 'Ëìù': 'l√°n', 'Áªø': 'l«ú', 'ÁôΩ': 'b√°i', 'Èªë': 'hƒìi',
        'Ê≤≥': 'h√©', 'ÊµÅ': 'li√∫', 'Êµ∑': 'h«éi', 'Ê¥ã': 'y√°ng', 'ÂÖ¨': 'g≈çng', 'Ë∑Ø': 'l√π',
        '‰ª¨': 'men', 'Âõæ': 't√∫', 'ËàÖ': 'ji√π', 'Âß®': 'y√≠', '‰ºØ': 'b√≥', 'Âèî': 'sh≈´',
        'Âßë': 'g≈´', 'Ëµ∑': 'q«ê', 'Á´ã': 'l√¨', 'Âùê': 'zu√≤', '‰∏æ': 'j«î',
    }
    
    # Common word pinyin for better accuracy
    common_pinyin = {
        "Êôö‰∏ä": "w«én shang", "Êó©‰∏ä": "z«éo shang", "‰∏≠Âçà": "zh≈çng w«î", "‰∏ãÂçà": "xi√† w«î",
        "Ë∞¢Ë∞¢": "xi√® xie", "‰Ω†Â•Ω": "n«ê h«éo", "ÂÜçËßÅ": "z√†i ji√†n", "ÂØπ‰∏çËµ∑": "du√¨ bu q«ê",
        "Â≠¶Ê†°": "xu√© xi√†o", "ËÄÅÂ∏à": "l«éo shƒ´", "Â≠¶Áîü": "xu√© sheng", "ÊúãÂèã": "p√©ng you",
        "Ê≤≥ÊµÅ": "h√© li√∫", "Êµ∑Ê¥ã": "h«éi y√°ng", "ÂÖ¨Ë∑Ø": "g≈çng l√π", "ÁîªÂõæ": "hu√† t√∫",
        "‰ª¨": "men", "ËàÖËàÖ": "ji√π jiu", "ÈòøÂß®": "ƒÅ y√≠", "‰ºØ‰ºØ": "b√≥ bo", 
        "ÂèîÂèî": "sh≈´ shu", "ÂßëÂßë": "g≈´ gu", "Ëµ∑Á´ã": "q«ê l√¨", "Âùê‰∏ã": "zu√≤ xi√†", 
        "‰∏æÊâã": "j«î sh«íu",
    }
    
    if word in common_pinyin:
        return common_pinyin[word]
    
    pinyin_parts = []
    for char in word:
        pinyin_parts.append(pinyin_map.get(char, char))
    return " ".join(pinyin_parts)

def generate_audio(text):
    """Generate audio using gTTS"""
    try:
        audio_buffer = io.BytesIO()
        tts = gTTS(text=text, lang='zh-cn')
        tts.write_to_fp(audio_buffer)
        audio_buffer.seek(0)
        return audio_buffer
    except Exception as e:
        st.error(f"Audio generation failed: {e}")
        return None

def get_word_details(word):
    """Get detailed information for a word, with Google Translate fallback"""
    if word in st.session_state.word_details:
        return st.session_state.word_details[word]
    
    # Step 1: Try online dictionary
    online_result = search_online_dictionary(word)
    if online_result:
        result = online_result
        source = f"Online - {online_result['source']}"
    else:
        # Step 2: Try Google Translate API
        translated_meaning = google_translate_chinese_to_english(word)
        if translated_meaning and translated_meaning != "Translation unavailable":
            result = {
                "pinyin": generate_smart_pinyin(word),
                "meaning": translated_meaning
            }
            source = "Google Translate"
        else:
            # Step 3: Fallback to internal smart meaning
            result = {
                "pinyin": generate_smart_pinyin(word),
                "meaning": generate_smart_meaning(word)
            }
            source = "Smart Analysis (Offline)"
    
    st.session_state.word_details[word] = {
        **result,
        "source": source
    }
    
    return st.session_state.word_details[word]

def display_word_details(word):
    """Display detailed information for a single word"""
    details = get_word_details(word)
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader(f"üìñ {word}")
        st.info(f"**Pinyin:** {details['pinyin']}")
        st.info(f"**Meaning:** {details['meaning']}")
        st.info(f"**Source:** {details['source']}")
    
    with col2:
        st.subheader("üéµ Pronunciation")
        audio_buffer = generate_audio(word)
        if audio_buffer:
            st.audio(audio_buffer, format='audio/mp3')
            st.download_button(
                "üì• Download Audio",
                audio_buffer.getvalue(),
                file_name=f"{word}_pronunciation.mp3",
                mime="audio/mp3",
                key=f"audio_{word}"
            )

# MAIN APP
st.title("üîç Chinese Dictionary Explorer Done by Sandar")
st.markdown("Type Chinese words OR upload files to get meanings and audio pronunciation")

# MANUAL TEXT INPUT - PROMINENTLY DISPLAYED
st.header("üìù Type Chinese Words Here")
st.markdown("Enter Chinese words or text below (separated by spaces or new lines):")

manual_input = st.text_area(
    "Chinese Text Input:",
    placeholder="Type or paste Chinese words here...\nExamples: ‰Ω†Â•Ω Ë∞¢Ë∞¢ ÊàëÁà±‰Ω† ÊúãÂèã Â≠¶Ê†°\nOr: ‰Ω†Â•ΩÔºåÊàëÊòØÂ≠¶Áîü„ÄÇÊàëÂñúÊ¨¢Â≠¶‰π†‰∏≠Êñá„ÄÇ",
    height=120,
    key="manual_input_main"
)

col1, col2, col3 = st.columns([2, 2, 1])
with col1:
    process_manual = st.button("‚ú® Process Text", type="primary", use_container_width=True)
with col2:
    clear_manual = st.button("üóëÔ∏è Clear Text", use_container_width=True)
with col3:
    st.write("")  # Spacing

if process_manual and manual_input:
    with st.spinner("Extracting Chinese words..."):
        manual_words = extract_individual_chinese_words(manual_input)
        st.session_state.manual_words = manual_words
    
    if manual_words:
        st.success(f"‚úÖ Found {len(manual_words)} Chinese words: {', '.join(manual_words)}")

        # Automatically display their meanings using Google Translate
        for word in manual_words:
            st.markdown("---")
            display_word_details(word)
        
        st.session_state.scanned_words = []  # Clear file upload words
    else:
        st.warning("‚ùå No Chinese words found in the text")

if clear_manual:
    st.session_state.manual_words = []
    st.rerun()

# FILE UPLOAD SECTION
st.header("üìé Or Upload Files")
st.markdown("Upload images or text files to extract Chinese words using OCR")

uploaded_file = st.file_uploader(
    "Choose image or text file",
    type=['png', 'jpg', 'jpeg', 'txt'],
    help="Supported: PNG, JPG, JPEG images or TXT files"
)

if uploaded_file is not None:
    with st.spinner("Processing file..."):
        words, extracted_text = process_uploaded_file(uploaded_file)
        st.session_state.scanned_words = words
        st.session_state.extracted_text = extracted_text
    
    if words:
        st.success(f"‚úÖ Found {len(words)} Chinese words: {', '.join(words)}")
        st.session_state.manual_words = []  # Clear manual input words
    else:
        st.warning("‚ùå No Chinese words found")
        
    if st.session_state.extracted_text:
        with st.expander("View Extracted Text"):
            st.text_area("OCR Result", st.session_state.extracted_text, height=150, key="extracted_text")

# QUICK SEARCH
st.header("üîç Quick Single Word Search")
quick_col1, quick_col2 = st.columns([3, 1])
with quick_col1:
    single_word = st.text_input("Enter one Chinese word:", placeholder="Example: ‰Ω†Â•Ω", key="single_word")
with quick_col2:
    st.write("")
    st.write("")
    quick_search = st.button("Search", use_container_width=True)

if quick_search and single_word:
    if re.search(r'[\u4e00-\u9fff]', single_word):
        st.markdown("---")
        st.subheader(f"Quick Result: {single_word}")
        display_word_details(single_word.strip())
    else:
        st.warning("Please enter a Chinese character")

# DISPLAY RESULTS
st.markdown("---")
st.header("üìö Processing Results")

# Combine words from both sources
all_words = st.session_state.scanned_words + st.session_state.manual_words

if all_words:
    st.success(f"üéâ Processing {len(all_words)} words")
    
    for i, word in enumerate(all_words):
        st.markdown("---")
        display_word_details(word)
        
else:
    st.info("üëÜ Enter Chinese words above or upload a file to get started")
    
    # Sample words
    st.markdown("### üí° Try these sample words:")
    cols = st.columns(4)
    sample_words = ["‰Ω†Â•Ω", "Ë∞¢Ë∞¢", "ÊàëÁà±‰Ω†", "ÊúãÂèã", "Â≠¶Ê†°", "Â¶àÂ¶à", "ËÄÅÂ∏à", "Â≠¶Áîü"]
    
    for i, word in enumerate(sample_words):
        with cols[i % 4]:
            if st.button(word, use_container_width=True):
                st.session_state.manual_words = [word]
                st.rerun()

# Clear button
if all_words:
    if st.button("Clear All Words", type="secondary"):
        st.session_state.scanned_words = []
        st.session_state.manual_words = []
        st.session_state.extracted_text = ""
        st.rerun()

# Sidebar info
with st.sidebar:
    st.markdown("### üìä Current Status")
    st.write(f"Manual words: {len(st.session_state.manual_words)}")
    st.write(f"File words: {len(st.session_state.scanned_words)}")
    st.write(f"Total: {len(all_words)} words")
    
    st.markdown("### üéØ Features")
    st.write("‚Ä¢ Type Chinese words directly")
    st.write("‚Ä¢ Upload images/text files")
    st.write("‚Ä¢ Get pinyin & meanings")
    st.write("‚Ä¢ Audio pronunciation")
    st.write("‚Ä¢ Download audio files")
    
    st.markdown("### üîç New Words Added")
    st.write("‚Ä¢ ËàÖËàÖ, ÈòøÂß®, ‰ºØ‰ºØ, ÂèîÂèî, ÂßëÂßë")
    st.write("‚Ä¢ Ëµ∑Á´ã, Âùê‰∏ã, ‰∏æÊâã")
    st.write("‚Ä¢ And many more family terms!")
